# LLM API Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=codellama

# App Configuration
FLASK_ENV=development
DEBUG=True
PORT=5000
